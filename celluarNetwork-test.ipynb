{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "input_data = []\n",
    "target_data = []\n",
    "\n",
    "\n",
    "def buildNeuralNetwork():    \n",
    "    \n",
    "    # reading the data from users.csv file for L_<number>_x value and L_<number>\n",
    "    # and the target cell data L_1547777\n",
    "    \n",
    "    df = pd.read_csv('users.csv', sep = ';',\n",
    "                     usecols = ['L1132038','L1143298','L1322753','L1384705','L1391361',\n",
    "                                'L1456129','L1547777','L1598466','L1618689','L1618690',\n",
    "                                'L264453','L264454'],\n",
    "                     skip_blank_lines=True )\n",
    "    \n",
    "    names = df.head(508)\n",
    "    print(names)\n",
    "    \n",
    "    #np.genfromtxt('users.csv',delimiter=';')\n",
    "        \n",
    "    xdata = pd.read_csv('users.csv', sep = ';', \n",
    "                        usecols = ['L1547777_x','L1022212_x','L1100545_x',\n",
    "                                   'L1132034_x','L1132035_x','L1143298_x',\n",
    "                                   'L1384705_x','L264453_x','L264454_x', 'L1547777'],\n",
    "                        skip_blank_lines=True, skiprows=range(1,498) )\n",
    "    \n",
    "    xvalues = xdata.head(100)\n",
    "    #print(xvalues)\n",
    "    \n",
    "    target_number = df['L1547777']\n",
    "    target_data.append(target_number)\n",
    "    output = np.array(target_data)    \n",
    "    \n",
    "    xdata_number = df['L1132038']\n",
    "    input_data.append(xdata_number)\n",
    "    \n",
    "    xdata_number = df['L1322753']\n",
    "    input_data.append(xdata_number)\n",
    "    \n",
    "    xdata_number = df['L1391361']\n",
    "    input_data.append(xdata_number)\n",
    "    \n",
    "    xdata_number = df['L1598466']\n",
    "    input_data.append(xdata_number)\n",
    "    \n",
    "    xdata_number = df['L1618690']    \n",
    "    input_data.append(xdata_number)\n",
    "    \n",
    "    xdata_number = df['L264454']\n",
    "    input_data.append(xdata_number)\n",
    "    \n",
    "    data = np.array(input_data)    \n",
    "    \n",
    "    # variable initialization\n",
    "    numberOfIterations = 5000\n",
    "    #Setting learning rate    \n",
    "    learningRate=0.2\n",
    "    \n",
    "    #Building a Neural Network\n",
    "    #hiddenlayers_neurons = 3\n",
    "    \n",
    "    #forward Propogation:    \n",
    "    weights1 = np.random.randn()\n",
    "    weights2 = np.random.randn()\n",
    "    bias  = np.random.randn()\n",
    "\n",
    "    # plotting the scatter data\n",
    "    pyplot.axis([0,62,0,62])\n",
    "    pyplot.grid()   \n",
    "       \n",
    "    for i in range(0, len(data)):\n",
    "        point = data[i]\n",
    "      \n",
    "        # weighted averge of points features and bias\n",
    "        points1 = float(point[0].replace(',', '.'))\n",
    "        points2 = float(point[1].replace(',', '.'))\n",
    "\n",
    "        #Sum of the weights + bias     \n",
    "        z = (points1 * weights1) + (points2 * weights2) + bias\n",
    "        print(\"sum of the weights + bias\", z)\n",
    "\n",
    "        # Activation function on z ( non-linear transformation)\n",
    "        prediction = sigmoid(z)\n",
    "\n",
    "        # Back propogation \n",
    "        # Finding the cost function\n",
    "        target = output[0][i]\n",
    "        targetPoint = float(target[0].replace(',', '.'))\n",
    "\n",
    "        costs = np.square(prediction - targetPoint)        \n",
    "        #pyplot.plot(costs)\n",
    "\n",
    "        pyplot.scatter(points1, points2, targetPoint, c=\"b\")    \n",
    "\n",
    "        # square the difference of prediction - target\n",
    "        derivative_costs = 2 * (prediction - targetPoint)\n",
    "\n",
    "        # derivate of prediction\n",
    "        derivative_z = sigmoid_dervt(z)\n",
    "\n",
    "        # training the data ; training algorithm for a neural network (to minimize the error)\n",
    "        # predication close to target              \n",
    "\n",
    "    return\n",
    "        \n",
    "#Sigmoid Function\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "# derivate of Sigmoid Function\n",
    "def sigmoid_dervt(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x)) \n",
    "\n",
    "def add_data_list(number):\n",
    "    input_data.append(number)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    L1132038 L1143298 L1322753 L1384705 L1391361 L1456129 L1547777 L1598466  \\\n",
      "0       3,15      4,4    12,19    10,46    17,17    43,11     6,31     3,86   \n",
      "1       3,41      1,8      8,8     7,55    14,66    29,97     4,14     3,57   \n",
      "2       2,25      1,5     7,02     5,76    11,54    25,44     3,95     2,36   \n",
      "3       2,13     1,25     6,53     3,67    10,93    23,03      4,3     2,46   \n",
      "4        2,9     1,68     6,23     3,58    10,75    20,12     4,54     2,01   \n",
      "5       2,32     2,43     7,04     3,63     11,4    21,95      3,7        2   \n",
      "6        3,4     3,42     9,65     5,41     14,1    26,13     5,31     3,22   \n",
      "7       8,77     2,78    14,41     7,58    19,47    29,82      7,1     2,71   \n",
      "8      18,61     2,98    24,61    11,12    20,34    32,39     8,67     2,33   \n",
      "9      25,85     2,75    36,08    12,78     19,5    31,27    10,37     1,81   \n",
      "10        30     4,22    36,64     9,71    16,98    36,77     8,67     2,35   \n",
      "11     27,29     5,64    34,71     15,9    17,76    39,65     8,39     2,72   \n",
      "12     28,77     3,33    30,56    12,24    18,23    36,22     8,13     2,17   \n",
      "13     27,39     4,34    27,95    11,58    18,58    32,38     9,65      1,4   \n",
      "14     27,45     4,19       27    11,57    18,71    34,82     9,75     1,11   \n",
      "15     23,04     3,65    24,04    14,95    19,37    39,07      8,9     1,69   \n",
      "16     12,64     4,14    19,88    15,39    23,08    47,02     8,69      1,4   \n",
      "17      8,23     4,54    19,48    15,26    26,64    47,61    10,95     1,84   \n",
      "18      8,16     5,35    20,18    18,42    26,74    55,25    12,42     2,62   \n",
      "19      6,38     4,46    21,07    17,37    26,46    54,17    15,28     2,16   \n",
      "20      7,66     4,34    23,85    15,41    30,96    58,67    15,66     2,03   \n",
      "21      8,46     5,47    27,45    18,19    34,29    61,71    13,76     2,33   \n",
      "22      7,12     6,46    26,27    19,91    33,49    64,12    13,48     1,81   \n",
      "23      6,16     3,91    22,05    13,11    27,09       53    10,46     1,05   \n",
      "24      2,89     2,87    17,86    10,11    20,04    44,93     9,41     0,49   \n",
      "25      2,75     1,93    14,33     8,37    15,69    34,17     7,99     0,27   \n",
      "26       2,6     2,03    12,92     7,64    12,96    24,86        6     0,23   \n",
      "27      2,28     0,87    11,49     5,71    10,66    22,43     4,81     0,74   \n",
      "28      2,01     0,47    10,08     5,09     9,36    22,94      5,1     0,81   \n",
      "29      3,04     1,02    10,19     4,92    10,16       23      4,3     0,36   \n",
      "..       ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "478     3,87     2,56    10,48     7,12    15,22    35,82     3,16     1,66   \n",
      "479     3,58     1,57     8,86     5,45    12,72    28,22     2,42     1,94   \n",
      "480     2,52     0,85     7,03     3,83     9,79    22,92     1,94     1,27   \n",
      "481     2,22     0,71      6,8     3,17    10,44    19,51     2,34     1,37   \n",
      "482        4     1,23     7,04     3,31     9,01    22,93     1,97      1,6   \n",
      "483     5,98     1,52    10,18     5,53    11,89    24,13     3,71     1,53   \n",
      "484     9,53      2,7    12,73     8,31    16,88       28     5,48      2,3   \n",
      "485    18,66     3,91    23,99     7,92    17,54    35,71     6,56     2,56   \n",
      "486    28,27     3,49    27,96     7,92    17,68    33,05      5,7     1,97   \n",
      "487     24,4     4,64    25,14     9,46    19,96    34,76      7,5     1,47   \n",
      "488    26,39     4,41    29,34     9,85    19,44    37,64     7,11     2,61   \n",
      "489    27,49        4    30,86    12,25    16,85    40,67     6,14     2,74   \n",
      "490    32,29     4,12    26,43    11,14    17,91    42,42     6,56      2,4   \n",
      "491    30,44      3,5    18,66    12,31    16,26    40,14     6,29     3,74   \n",
      "492    25,32     3,55    19,94    11,09    20,39    34,68      7,3     4,15   \n",
      "493     15,2     3,22    18,53     9,99    23,11    40,48     7,73     3,19   \n",
      "494    10,32     5,24    20,23    11,25    22,89    46,97     8,14     3,45   \n",
      "495     8,48     5,52    18,16    11,52    20,93    56,49     9,31     3,74   \n",
      "496     7,15     4,92    19,27    12,17    23,74    57,83     9,23     4,64   \n",
      "497     7,15      4,6    18,68    12,15    26,83    60,33      9,6     4,28   \n",
      "498     9,23    10,11    21,02    30,02    31,79    75,05    12,59     4,04   \n",
      "499     6,97    12,86    17,53    40,92    29,83    70,67    19,37     6,05   \n",
      "500     4,38     8,69     16,6    37,89    25,38    57,81    20,75     4,39   \n",
      "501     4,05     3,41    10,68    14,21    23,98    50,89     8,73     3,25   \n",
      "502     2,86     2,94    10,03     7,39    16,62    34,38     4,94      2,7   \n",
      "503     2,68     1,49      8,3     7,18    13,37    30,82     4,18     2,83   \n",
      "504     2,47     0,67     8,59     5,01    10,94    26,95     3,05     2,57   \n",
      "505     2,42     0,41     7,65     3,34    11,14    24,71     2,72     2,37   \n",
      "506     2,83     0,67     8,82      3,6    10,41    26,44     3,24     2,29   \n",
      "507     4,09     1,66     11,1     4,65    13,52    27,79     4,21     2,25   \n",
      "\n",
      "    L1618689 L1618690 L264453 L264454  \n",
      "0      13,34    17,68       0       0  \n",
      "1       9,54    10,57       0       0  \n",
      "2       7,64     9,14       0       0  \n",
      "3       5,82     8,21       0       0  \n",
      "4       5,18     7,87       0       0  \n",
      "5       7,19     7,17       0    0,09  \n",
      "6      12,22     9,94       0    0,36  \n",
      "7      22,59     12,9       0     0,7  \n",
      "8      28,81    13,51       0     1,1  \n",
      "9      22,96    13,85       0    0,75  \n",
      "10     19,85    14,99       0     0,4  \n",
      "11     22,02    11,61    0,01    0,45  \n",
      "12     22,31     10,8       0    0,38  \n",
      "13     21,89    11,24       0    0,45  \n",
      "14     22,02    12,49    0,02    0,54  \n",
      "15     29,76    12,05    0,01    0,75  \n",
      "16      31,2    12,58    0,02     0,8  \n",
      "17     26,13    17,61    0,02    0,58  \n",
      "18     29,01     21,2       0    0,46  \n",
      "19     26,64    22,09       0    0,32  \n",
      "20     25,57    22,38    0,01    0,26  \n",
      "21     22,55    28,03    0,01    0,19  \n",
      "22     25,68    34,98       0    0,11  \n",
      "23     21,62    28,26       0    0,07  \n",
      "24     16,23    17,41       0       0  \n",
      "25      10,4     13,5       0       0  \n",
      "26      7,79     10,6       0       0  \n",
      "27      5,26    10,33       0       0  \n",
      "28      5,66    10,93       0       0  \n",
      "29      7,21    10,74       0     0,1  \n",
      "..       ...      ...     ...     ...  \n",
      "478     7,46    13,11       0       0  \n",
      "479     5,94     9,98       0       0  \n",
      "480        5     8,07       0       0  \n",
      "481     5,61     7,55       0       0  \n",
      "482     6,08     8,52       0    0,08  \n",
      "483    12,21      8,6       0    0,38  \n",
      "484    18,17    13,29    0,01     0,6  \n",
      "485    26,31    11,61    0,01    1,27  \n",
      "486    20,58       14    0,01    0,74  \n",
      "487    18,08    11,51       0    0,36  \n",
      "488    19,43     10,9       0     0,3  \n",
      "489    20,64    13,58    0,02    0,41  \n",
      "490    20,63    11,09       0    0,28  \n",
      "491    21,59     11,8       0    0,45  \n",
      "492    25,54     12,1    0,02    0,64  \n",
      "493     29,9    16,16    0,03    0,82  \n",
      "494    29,49    14,79    0,01    0,64  \n",
      "495    23,47    20,11    0,01    0,52  \n",
      "496    21,77    20,71    0,01    0,25  \n",
      "497    20,13    21,36       0    0,23  \n",
      "498    17,11    24,67       0    0,18  \n",
      "499    16,37    25,47       0    0,09  \n",
      "500    13,79    23,53       0    0,06  \n",
      "501    10,21    15,96       0       0  \n",
      "502     6,68    12,28       0       0  \n",
      "503     6,59     9,52       0       0  \n",
      "504     5,28     8,98       0       0  \n",
      "505     6,52     8,66       0       0  \n",
      "506     8,27     9,02       0    0,13  \n",
      "507    13,92    10,69       0    0,35  \n",
      "\n",
      "[508 rows x 12 columns]\n",
      "sum of the weights + bias 0.7607690331050834\n",
      "sum of the weights + bias -0.10347095058595744\n",
      "sum of the weights + bias 1.2549217386998783\n",
      "sum of the weights + bias 0.5257798529371349\n",
      "sum of the weights + bias -1.5823684263544078\n",
      "sum of the weights + bias 0.08978722452972644\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "buildNeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
